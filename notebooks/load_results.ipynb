{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DDE_BACKEND=tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: tensorflow\n",
      "Other supported backends: tensorflow.compat.v1, pytorch, jax, paddle.\n",
      "paddle supports more examples now and is recommended.\n"
     ]
    }
   ],
   "source": [
    "%env DDE_BACKEND=tensorflow\n",
    "import tensorflow as tf\n",
    "import deepxde as dde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.domains import NewtonianParallelPlane\n",
    "from models.rheology import NewtonianFluid\n",
    "from models.PINN import PINNParameters\n",
    "from models.neural_network import NeuralNetwork, ADAMOptimizer, LBFGSOptimizer\n",
    "from models.data import TrainingData, NeuralNetworkModel\n",
    "\n",
    "rheology = NewtonianFluid(mu=1, density=1)\n",
    "domain = NewtonianParallelPlane(distance=1, length=1, inlet_velocity=1, rheology=rheology)\n",
    "boundary_conditions = domain.build_boundary_conditions()\n",
    "neural_network = NeuralNetwork(\n",
    "    adam_optimizer=ADAMOptimizer(iterations=100, report_frequency=100),\n",
    "    LBFGS_optimizer=LBFGSOptimizer(max_iterations=100, report_frequency=100)\n",
    ")\n",
    "pinn_parameters = PINNParameters(\n",
    "    domain_points=100,\n",
    "    boundary_points=100,\n",
    "    number_of_test=100, \n",
    ")\n",
    "net = neural_network.build_net()\n",
    "training_data = TrainingData(domain=domain, boundary_condition_list=[v for v in boundary_conditions.values()], pinn_parameters=pinn_parameters)\n",
    "model = NeuralNetworkModel(data=training_data.data, net=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "'compile' took 0.000468 s\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Pablo\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\deepxde-custom-4PBOT-FI-py3.10\\lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py:1469: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "model.compile_ADAM_model(learning_rate=neural_network.adam_optimizer.learning_rate)\n",
    "adam_output_path = pathlib.Path(\"./out/adam/model_state-100.ckpt.index\")\n",
    "model.model.restore(adam_output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepxde-custom-4PBOT-FI-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
